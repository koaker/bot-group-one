// AI è®¡ç®— Worker
// ä¸“é—¨è´Ÿè´£æ¥æ”¶æ¥è‡ªä¸»æœºå™¨äººçš„å¼‚æ­¥è¯·æ±‚ï¼Œè°ƒç”¨AIï¼Œå¹¶å¤„ç†ç»“æœ

// å…¨å±€é…ç½®
let CONFIG = {
  BOT_TOKEN: '',
  KV_NAMESPACE: 'TG_AUTOCCB_BOT',
  AI_SCAN_AUTO_DELETE: false,
};

// åˆå§‹åŒ–é…ç½®
function initConfig(env) {
  CONFIG.BOT_TOKEN = env.BOT_TOKEN || '';
  CONFIG.KV_NAMESPACE = env.KV_NAMESPACE || 'TG_AUTOCCB_BOT';
  CONFIG.AI_SCAN_AUTO_DELETE = env.AI_SCAN_AUTO_DELETE === 'true';
}

// Telegram API (ä¸ä¸»Workerç›¸åŒ)
class TelegramAPI {
  static async request(method, params = {}) {
    const url = `https://api.telegram.org/bot${CONFIG.BOT_TOKEN}/${method}`;
    const response = await fetch(url, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(params),
    });
    return await response.json();
  }

  static async sendMessage(chatId, text, options = {}) {
    return this.request('sendMessage', { chat_id: chatId, text, ...options });
  }

  static async editMessageText(chatId, messageId, text, options = {}) {
    return this.request('editMessageText', { chat_id: chatId, message_id: messageId, text, ...options });
  }

  static async deleteMessage(chatId, messageId) {
    return this.request('deleteMessage', { chat_id: chatId, message_id: messageId });
  }
}

// AIæœåŠ¡ç±» (ä¸ä¸»Workerç›¸åŒ)
class AIService {
  static async getAIConfig(kv) {
    try {
      const config = await kv.get('ai:config');
      return config ? JSON.parse(config) : {
        provider: 'openai',
        model: 'gpt-3.5-turbo',
        endpoint: 'https://api.openai.com/v1/chat/completions',
        apiKey: '',
        enabled: false,
        customReply: true
      };
    } catch (error) {
      console.error('è·å–AIé…ç½®å¤±è´¥:', error);
      return null;
    }
  }

  static getNestedValue(obj, path) {
    if (!path) return obj;
    const keys = path.split('.');
    return keys.reduce((o, key) => (o && o[key] !== undefined) ? o[key] : undefined, obj);
  }

  static async callAI(prompt, content, kv) {
    const config = await this.getAIConfig(kv);
    if (!config || !config.enabled || !config.apiKey) {
      throw new Error('AIæœåŠ¡æœªå¯ç”¨æˆ–æœªé…ç½®APIå¯†é’¥');
    }

    let messages;
    let endpoint = config.endpoint;
    let requestBody;
    let headers = {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${config.apiKey}`
    };

    if (config.provider === 'claude') {
      messages = [{ role: 'user', content: `${prompt}\n\n---\n\n${content}` }];
      headers['anthropic-version'] = '2023-06-01';
      requestBody = { model: config.model, messages, max_tokens: 200 };
    } else if (config.provider === 'gemini') {
      messages = [{ role: 'user', parts: [{ text: `${prompt}\n\n---\n\n${content}` }] }];
      endpoint = `${config.endpoint}?key=${config.apiKey}`;
      requestBody = { contents: messages };
      delete headers['Authorization'];
    } else { // OpenAI and compatible
      messages = [
        { role: 'system', content: prompt },
        { role: 'user', content: content }
      ];
      requestBody = { model: config.model, messages, max_tokens: 200 };
    }
    
    if (config.provider === 'custom' && config.customParams) {
        requestBody = { ...requestBody, ...config.customParams };
    }
    if (config.provider === 'custom' && config.customHeaders) {
        headers = { ...headers, ...config.customHeaders };
    }

    const response = await fetch(endpoint, {
      method: 'POST',
      headers: headers,
      body: JSON.stringify(requestBody)
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`AI APIè¯·æ±‚å¤±è´¥: ${response.status} ${response.statusText} - ${errorText}`);
    }

    const data = await response.json();
    let result;
    if (config.provider === 'claude') {
      result = data.content?.[0]?.text;
    } else if (config.provider === 'gemini') {
      result = data.candidates?.[0]?.content?.parts?.[0]?.text;
    } else if (config.provider === 'custom' && config.responsePath) {
      result = this.getNestedValue(data, config.responsePath);
    } else { // Default OpenAI
      result = data.choices?.[0]?.message?.content;
    }

    if (!result) {
      throw new Error('æœªèƒ½ä»AIå“åº”ä¸­æå–å†…å®¹');
    }
    return result.trim();
  }
}


// å¤„ç†AIæ‰«æä»»åŠ¡
async function handleAIScan(data, kv) {
  const { text, msg, chatId, aiCustomPrompt } = data;
  try {
    const aiResult = await AIService.callAI(aiCustomPrompt, text, kv);
    console.log(`AIæ‰«æç»“æœ for msg ${msg.message_id}: ${aiResult}`);

    if (aiResult.startsWith('ã€è¿è§„ã€‘')) {
      const replyText = aiResult.replace('ã€è¿è§„ã€‘', '').trim();
      
      // å‘é€è¿è§„æç¤º
      await TelegramAPI.sendMessage(chatId, `Hey @${msg.from.username || msg.from.first_name},\n\n${replyText}`, {
        reply_to_message_id: msg.message_id
      });

      // å¦‚æœé…ç½®äº†è‡ªåŠ¨åˆ é™¤ï¼Œåˆ™åˆ é™¤åŸæ¶ˆæ¯
      if (CONFIG.AI_SCAN_AUTO_DELETE) {
        await TelegramAPI.deleteMessage(chatId, msg.message_id);
      }
    }
    // å¦‚æœæ˜¯"æ­£å¸¸"ï¼Œåˆ™ä¸è¿›è¡Œä»»ä½•æ“ä½œ
  } catch (error) {
    console.error(`å¤„ç†AIæ‰«æä»»åŠ¡å¤±è´¥ for msg ${msg.message_id}:`, error);
    // åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬é€‰æ‹©é™é»˜å¤±è´¥ï¼Œä¸æ‰“æ‰°ç”¨æˆ·
  }
}

// å¤„ç†AIæµ‹è¯•ä»»åŠ¡
async function handleAITest(data, kv) {
  const { testContent, msg, chatId, notificationMsgId } = data;
  try {
    // å¯¹äºæµ‹è¯•ï¼Œæˆ‘ä»¬ä¸éœ€è¦ç³»ç»Ÿæç¤ºè¯ï¼Œç›´æ¥å‘é€å†…å®¹
    const aiResult = await AIService.callAI("You are a helpful assistant.", testContent, kv);
    const replyText = `âœ… AIæµ‹è¯•æˆåŠŸ\n\nğŸ“ è¾“å…¥:\n${testContent}\n\nğŸ¤– AIå›å¤:\n${aiResult}`;
    
    if (notificationMsgId) {
      await TelegramAPI.editMessageText(chatId, notificationMsgId, replyText);
    } else {
      await TelegramAPI.sendMessage(chatId, replyText, { reply_to_message_id: msg.message_id });
    }
  } catch (error) {
    console.error(`å¤„ç†AIæµ‹è¯•ä»»åŠ¡å¤±è´¥:`, error);
    const errorText = `âŒ AIæµ‹è¯•å¤±è´¥\n\nåŸå› : ${error.message}`;
    if (notificationMsgId) {
      await TelegramAPI.editMessageText(chatId, notificationMsgId, errorText);
    } else {
      await TelegramAPI.sendMessage(chatId, errorText, { reply_to_message_id: msg.message_id });
    }
  }
}


// å®šä¹‰CORSå“åº”å¤´
const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Methods': 'POST, OPTIONS',
  'Access-Control-Allow-Headers': '*', // å…è®¸æ‰€æœ‰å¤´éƒ¨ï¼Œå¢å¼ºå…¼å®¹æ€§
};

export default {
  async fetch(request, env, ctx) {
    // ç›´æ¥å¤„ç†CORSé¢„æ£€è¯·æ±‚
    if (request.method === 'OPTIONS') {
      return new Response(null, { headers: corsHeaders });
    }

    if (request.method !== 'POST') {
      return new Response('Expected POST', { status: 405, headers: corsHeaders });
    }

    try {
      // åˆå§‹åŒ–é…ç½®
      initConfig(env);
      const kv = env[CONFIG.KV_NAMESPACE];

      if (!kv) {
        console.error("KV Namespaceæœªç»‘å®š");
        return new Response('KV Namespace not configured', { status: 500, headers: corsHeaders });
      }
      
      const body = await request.json();
      
      switch (body.type) {
        case 'ai_scan':
          ctx.waitUntil(handleAIScan(body.data, kv));
          break;
        case 'ai_test':
          ctx.waitUntil(handleAITest(body.data, kv));
          break;
        default:
          return new Response('Unknown task type', { status: 400, headers: corsHeaders });
      }

      // ç«‹å³è¿”å›æˆåŠŸå“åº”ç»™ä¸»Workerï¼Œå¹¶é™„å¸¦CORSå¤´
      return new Response(JSON.stringify({ success: true, message: "Task received" }), {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      });

    } catch (error) {
      console.error('AI Workerå¤„ç†å¤±è´¥:', error);
      return new Response(error.message, { status: 500, headers: corsHeaders });
    }
  }
};